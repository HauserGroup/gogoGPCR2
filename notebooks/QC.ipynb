{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ff1a41b-3f35-4f4b-ac35-ca8785421b1f",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import hail as hl\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pyspark\n",
        "import dxpy\n",
        "import pandas as pd\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8435e5b6-a1cf-4611-b0b2-253d687f4ce2",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/cluster/dnax/jars/dnanexus-api-0.1.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/cluster/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-05 07:46:13.074 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "2023-09-05 07:46:14.362 WARN  Utils:69 - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 43000. Attempting port 43001.\n",
            "2023-09-05 07:46:14.731 WARN  MetricsReporter:84 - No metrics configured for reporting\n",
            "2023-09-05 07:46:14.732 WARN  LineProtoUsageReporter:48 - Telegraf configurations: url [metrics.push.telegraf.hostport], user [metrics.push.telegraf.user] or password [metrics.push.telegraf.password] missing.\n",
            "2023-09-05 07:46:14.732 WARN  MetricsReporter:117 - metrics.scraping.httpserver.port\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pip-installed Hail requires additional configuration options in Spark referring\n",
            "  to the path to the Hail Python module directory HAIL_DIR,\n",
            "  e.g. /path/to/python/site-packages/hail:\n",
            "    spark.jars=HAIL_DIR/backend/hail-all-spark.jar\n",
            "    spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar\n",
            "    spark.executor.extraClassPath=./hail-all-spark.jar"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log4j: Parsing for [root] with value=[INFO, logfile].\n",
            "log4j: Level token is [INFO].\n",
            "log4j: Category root set to INFO\n",
            "log4j: Parsing appender named \"logfile\".\n",
            "log4j: Parsing layout options for \"logfile\".\n",
            "log4j: Setting property [conversionPattern] to [%d{yyyy-MM-dd HH:mm:ss.SSS} %c{1}: %p: %m%n].\n",
            "log4j: End of parsing for \"logfile\".\n",
            "log4j: Setting property [append] to [false].\n",
            "log4j: Setting property [threshold] to [INFO].\n",
            "log4j: Setting property [file] to [/opt/notebooks/gogoGPCR2/hail_logs/DRD2_0746.log].\n",
            "log4j: setFile called: /opt/notebooks/gogoGPCR2/hail_logs/DRD2_0746.log, false\n",
            "log4j: setFile ended\n",
            "log4j: Parsed \"logfile\" options.\n",
            "log4j: Parsing for [Hail] with value=[INFO, HailSocketAppender].\n",
            "log4j: Level token is [INFO].\n",
            "log4j: Category Hail set to INFO\n",
            "log4j: Parsing appender named \"HailSocketAppender\".\n",
            "log4j: Parsed \"HailSocketAppender\" options.\n",
            "log4j: Handling log4j.additivity.Hail=[null]\n",
            "log4j: Finished configuring.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running on Apache Spark version 3.2.3\n",
            "SparkUI available at http://ip-10-60-170-194.eu-west-2.compute.internal:8081\n",
            "Welcome to\n",
            "     __  __     <>__\n",
            "    / /_/ /__  __/ /\n",
            "   / __  / _ `/ / /\n",
            "  /_/ /_/\\_,_/_/_/   version 0.2.116-cd64e0876c94\n",
            "LOGGING: writing to /opt/notebooks/gogoGPCR2/hail_logs/DRD2_0746.log\n"
          ]
        }
      ],
      "source": [
        "# Spark and Hail\n",
        "# @Peter this can probably stay as is\n",
        "\n",
        "DATABASE = \"matrix_tables\"\n",
        "REFERENCE_GENOME = \"GRCh38\"\n",
        "PROJ_NAME = \"DRD2\"\n",
        "\n",
        "Path(\"/tmp\").resolve().mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "LOG_FILE = (\n",
        "    Path(\"../hail_logs\", f\"{PROJ_NAME}_{datetime.now().strftime('%H%M')}.log\")\n",
        "    .resolve()\n",
        "    .__str__()\n",
        ")\n",
        "\n",
        "# Hail init\n",
        "sc = pyspark.SparkContext()\n",
        "spark = pyspark.sql.SparkSession(sc)\n",
        "\n",
        "hl.init(sc=sc, default_reference=REFERENCE_GENOME, log=LOG_FILE)\n",
        "\n",
        "# Create database in DNAX\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DATABASE} LOCATION 'dnax://'\")\n",
        "mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "78463193-fc1f-46f3-ba47-5018a6fc9f9c",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HGNC</th>\n",
              "      <th>entry_name</th>\n",
              "      <th>name</th>\n",
              "      <th>accession</th>\n",
              "      <th>family</th>\n",
              "      <th>species</th>\n",
              "      <th>residue_numbering_scheme</th>\n",
              "      <th>sequence</th>\n",
              "      <th>genes</th>\n",
              "      <th>ENSG</th>\n",
              "      <th>...</th>\n",
              "      <th>type</th>\n",
              "      <th>GRCh37_start</th>\n",
              "      <th>GRCh37_end</th>\n",
              "      <th>GRCh37_strand</th>\n",
              "      <th>GRCh38_start</th>\n",
              "      <th>GRCh38_end</th>\n",
              "      <th>GRCh38_strand</th>\n",
              "      <th>GRCh38_region</th>\n",
              "      <th>Notes</th>\n",
              "      <th>VCF_block</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HGNC</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DRD2</th>\n",
              "      <td>DRD2</td>\n",
              "      <td>drd2_human</td>\n",
              "      <td>D&lt;sub&gt;2&lt;/sub&gt; receptor</td>\n",
              "      <td>P14416</td>\n",
              "      <td>001_001_004_002</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>GPCRdb(A)</td>\n",
              "      <td>MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIA...</td>\n",
              "      <td>['DRD2']</td>\n",
              "      <td>ENSG00000149295</td>\n",
              "      <td>...</td>\n",
              "      <td>GPCR</td>\n",
              "      <td>113280318.0</td>\n",
              "      <td>113346413.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>113409605</td>\n",
              "      <td>113475691</td>\n",
              "      <td>-1</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows \u00d7 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      HGNC  entry_name                    name accession           family  \\\n",
              "HGNC                                                                        \n",
              "DRD2  DRD2  drd2_human  D<sub>2</sub> receptor    P14416  001_001_004_002   \n",
              "\n",
              "           species residue_numbering_scheme  \\\n",
              "HGNC                                          \n",
              "DRD2  Homo sapiens                GPCRdb(A)   \n",
              "\n",
              "                                               sequence     genes  \\\n",
              "HGNC                                                                \n",
              "DRD2  MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIA...  ['DRD2']   \n",
              "\n",
              "                 ENSG  ...  type GRCh37_start   GRCh37_end  GRCh37_strand  \\\n",
              "HGNC                   ...                                                  \n",
              "DRD2  ENSG00000149295  ...  GPCR  113280318.0  113346413.0           -1.0   \n",
              "\n",
              "      GRCh38_start  GRCh38_end  GRCh38_strand  GRCh38_region Notes VCF_block  \n",
              "HGNC                                                                          \n",
              "DRD2     113409605   113475691             -1             11   NaN        47  \n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read in metadata and region\n",
        "# Map genes to blocks and regions\n",
        "GENES = [\"DRD2\"]\n",
        "MAPPING_FILE = Path(\"../data/misc/mappings_with_blocks.tsv\").resolve()\n",
        "mapping = pd.read_csv(MAPPING_FILE, sep=\"\\t\").set_index(\"HGNC\", drop=False)\n",
        "mapping.loc[GENES, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78589c9-8967-4cef-823d-5c1b62b49df6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "fff3ef96-fabe-44cd-84c7-3555b3567bd2",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/cluster/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/cluster/dnax/jars/dnanexus-api-0.1.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]\n",
            "2023-09-01 13:06:48,956 WARN metrics.MetricsReporter: Unable to initialize metrics scraping configurations from hive-site.xml. Message:InputStream cannot be null\n",
            "2023-09-01 13:06:49,062 WARN service.DNAxApiSvc: Using default configurations. Unable to find dnanexus.conf.location=null\n",
            "2023-09-01 13:06:49,062 INFO service.DNAxApiSvc: apiserver connection-pool config. MaxPoolSize=10, MaxPoolPerRoute=10,MaxWaitTimeout=60000\n",
            "2023-09-01 13:06:49,062 INFO service.DNAxApiSvc: initializing http connection manager pools\n",
            "2023-09-01 13:06:49,211 INFO service.DNAxApiSvc: Worker process - IdleConnectionMonitorThread disabled\n",
            "2023-09-01 13:06:49,211 INFO service.DNAxApiSvc: Worker process - IdleConnectionMonitorThread disabled\n",
            "2023-09-01 13:06:49,211 INFO service.DNAxApiSvc: initializing DNAxApiSvc\n",
            "2023-09-01 13:06:49,903 WARN service.DNAxApiSvc: Shutting down Runtime service for Connection Pools\n",
            "2023-09-01 13:06:49,903 INFO service.DNAxApiSvc: shutting down httpClientConnManager\n",
            "2023-09-01 13:06:49,903 INFO service.DNAxApiSvc: shutting down httpsClientConnManager\n",
            "2023-09-01 13:06:51.264 Hail: INFO: Reading table without type imputation\n",
            "  Loading field 'f0' as type str (user-supplied)\n",
            "  Loading field 'f1' as type int32 (user-supplied)\n",
            "  Loading field 'f2' as type int32 (user-supplied)\n"
          ]
        }
      ],
      "source": [
        "INTERVAL_FILE = Path(\"../data/misc/xgen_plus_spikein.b38.bed\").resolve()\n",
        "subprocess.run([\"hadoop\", \"fs\", \"-put\", str(INTERVAL_FILE), \"/tmp\"])\n",
        "\n",
        "interval_table = hl.import_bed(\n",
        "    f\"/tmp/{INTERVAL_FILE.name}\",\n",
        "    reference_genome=\"GRCh38\",\n",
        ")\n",
        "\n",
        "# mt = mt.filter_rows(hl.is_defined(interval_table[mt.locus]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a087e26d-a043-4fe8-a3b1-c00bca0159e5",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# vcffile = \"file:///mnt/project/Bulk/Exome sequences/Population level exome OQFE\n",
        "# variants, pVCF format - final release/ukb23157_c1_b43_v1.vcf.gz\"\n",
        "# mt = hl.import_vcf(vcffile, force_bgz=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "b76971c1-4fb1-4c11-b1af-6a55db1f680b",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-01 13:07:00.570 Hail: INFO: Coerced sorted dataset                      \n",
            "2023-09-01 13:07:01.957 Hail: INFO: Coerced sorted dataset                      \n",
            "2023-09-01 13:07:03.961 Hail: INFO: wrote table with 15768 rows in 1 partition to /tmp/__iruid_9055-b6EcC8lCrQHrx4YEIEurzY\n",
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(937947, 469835)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mt.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3e2b9a-05d3-4792-a096-9b4fa1e9983d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
