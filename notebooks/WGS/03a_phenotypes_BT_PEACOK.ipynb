{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT TO OBTAIN PHENOTIPIC BINARY TREATS\n",
    "\n",
    "## This script should only be run once\n",
    "\n",
    "#### Initialization\n",
    "##### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "import dxdata\n",
    "import dxpy\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from pathlib import Path\n",
    "from src.phenotypes import get_pheno_fields, concatenate, new_names, get_age_sex\n",
    "\n",
    "Path(\"../tmp\").resolve().mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spark and dataset configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "dispensed_database_name = dxpy.find_one_data_object(\n",
    "    classname=\"database\", \n",
    "    name=\"app*\", folder=\"/\", name_mode=\"glob\", \n",
    "    describe=True\n",
    ")[\"describe\"][\"name\"]\n",
    "spark.sql(\"USE \" + dispensed_database_name)\n",
    "\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n",
    ")[\"id\"]\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "\n",
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "##### Retrieve binary values of given fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex_fields = get_age_sex(participant, fields=[\"31\", \"21022\"])\n",
    "\n",
    "binary_fields = get_pheno_fields(participant,\n",
    "    fields=[\n",
    "        \"131688\",\n",
    "        \"131690\",\n",
    "        \"130706\",\n",
    "        \"130708\",\n",
    "        \"130792\",\n",
    "        \"2443\",\n",
    "        \"131674\",\n",
    "        \"131676\",\n",
    "        \"2463\",\n",
    "        \"20511\",\n",
    "        \"1687\",\n",
    "        \"1697\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "field_names = concatenate([\"eid\"], age_sex_fields, binary_fields)\n",
    "\n",
    "df = participant.retrieve_fields(names=field_names, engine=dxdata.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_names(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Return updated column name for PEACOK use\n",
    "\n",
    "    Input(s):\n",
    "    - Field names\n",
    "\n",
    "    Output(s):\n",
    "    - Updated field names for PHESANT use\n",
    "    \"\"\"\n",
    "    s = s.replace(\"p\", \"\").replace(\"i\", \"\")\n",
    "\n",
    "    match = re.search(r\"_(\\d)$\", s)\n",
    "    \n",
    "    if match:\n",
    "        digit = match.group(1)\n",
    "        s = re.sub(r\"_(\\d)$\", \"\", s)  \n",
    "        s += f\"-0.{digit}\"            \n",
    "    else:\n",
    "        s += \"-0.0\"\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "colnames = [re.sub(\"_a\\d\", \"\", x) for x in df.columns]\n",
    "colnames = [\"xeid\"] + [new_names(s) for s in colnames[1:]]\n",
    "\n",
    "df = df.toDF(*colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export and upload DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"/tmp/phenos_BT.tsv\", sep=\"\\t\", header=True, emptyValue=\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -getmerge /tmp/phenos_BT.tsv ../tmp/phenos_PEACOK.BT.raw.tsv\n",
    "!dx upload ../tmp/phenos_PEACOK.BT.raw.tsv --path  /WGS_Javier/Data/phenotypes/ --brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/\\t/,/g' /mnt/project/WGS_Javier/Data/phenotypes/phenos_PEACOK.BT.raw.tsv > phenos_PEACOK.BT.raw.csv\n",
    "!dx upload phenos_PEACOK.BT.raw.csv --path  /WGS_Javier/Data/phenotypes/ --brief"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
