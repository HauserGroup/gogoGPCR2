{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223eef78-0583-48ea-ad5d-3bf3827b4a17",
   "metadata": {},
   "source": [
    "# Covariate Generation Script\n",
    "\n",
    "**Purpose:** Extract phenotypes, genetic principal components, genomic ancestry, and assessment center data to generate a covariate file for e.g. REGENIE.\n",
    "\n",
    "**Output:** A TSV file containing `FID`, `IID`, `SEX`, `AGE`, derived interaction terms, `ANCESTRY` (Genomic), `ASSESSMENT_CENTER`, and `PC1-PC20`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243aa73c-eb33-45dc-b529-735088ab6464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "import dxdata\n",
    "import dxpy\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "\n",
    "def fields_for_id(field_id, participant):\n",
    "    \"\"\"Retrieve and sort fields, robustly handling _i and _a indices.\"\"\"\n",
    "    fid_str = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=rf\"^p{fid_str}(_i\\d+)?(_a\\d+)?$\")\n",
    "\n",
    "    def get_sort_key(field):\n",
    "        i_match = re.search(r\"_i(\\d+)\", field.name)\n",
    "        a_match = re.search(r\"_a(\\d+)\", field.name)\n",
    "        return (\n",
    "            int(i_match.group(1)) if i_match else 0,\n",
    "            int(a_match.group(1)) if a_match else 0,\n",
    "        )\n",
    "\n",
    "    return sorted(fields, key=get_sort_key)\n",
    "\n",
    "\n",
    "def get_primary_column(df, field_id):\n",
    "    \"\"\"Finds the Instance 0 column (pXXXX_i0) for a field.\"\"\"\n",
    "    candidates = [c for c in df.columns if c.startswith(f\"p{field_id}\")]\n",
    "    # Sort by length and name to prioritize 'p54' or 'p54_i0' over 'p54_i1'\n",
    "    candidates.sort(key=lambda x: (len(x), x))\n",
    "    if not candidates:\n",
    "        raise ValueError(f\"Field {field_id} not found in dataframe\")\n",
    "    return candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99395fef-d79a-4ab1-a42d-149cb71a9415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- INITIALIZATION ---\n",
    "# Run once\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "# Load Dataset\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n",
    ")[\"id\"]\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447529d0-bcf9-413b-a513-e75b3683a448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data...\n",
      "Using Core Cols: p21022, p22001, and 20 PCs\n",
      "Using Extended Cols: p54_i0, p30079\n",
      "Participants in Core Set: 487713\n"
     ]
    }
   ],
   "source": [
    "# Get all column names\n",
    "# --- CONFIGURATION ---\n",
    "FIELD_IDS = {\n",
    "    \"AGE\": \"21022\",\n",
    "    \"SEX\": \"22001\",\n",
    "    \"PCS\": \"22009\",\n",
    "    \"ANCESTRY\": \"30079\",  # Genomic Ancestry (New), see https://doi.org/10.1101/2024.03.13.24303864\n",
    "    \"CENTER\": \"54\",  # Assessment Centre\n",
    "}\n",
    "\n",
    "\n",
    "all_fields = []\n",
    "\n",
    "for fid in FIELD_IDS.values():\n",
    "    all_fields.extend(fields_for_id(fid, participant))\n",
    "\n",
    "field_names = [\"eid\"] + [f.name for f in all_fields]\n",
    "\n",
    "print(\"Retrieving data...\")\n",
    "# coding_values=\"raw\" ensures Categories (like Center) are returned as Integers\n",
    "df_raw = participant.retrieve_fields(\n",
    "    names=field_names, engine=dxdata.connect(), coding_values=\"raw\"\n",
    ")\n",
    "\n",
    "# --- 2. DEFINE COLUMNS ---\n",
    "\n",
    "# Identify correct column names for Core vars\n",
    "col_age = get_primary_column(df_raw, FIELD_IDS[\"AGE\"])\n",
    "col_sex = get_primary_column(df_raw, FIELD_IDS[\"SEX\"])\n",
    "# Identify PC columns (Array 1 to 20)\n",
    "col_pcs = [\n",
    "    c\n",
    "    for c in df_raw.columns\n",
    "    if c.startswith(f\"p{FIELD_IDS['PCS']}_\") and int(c.split(\"_a\")[1]) <= 20\n",
    "]\n",
    "\n",
    "# Identify Extended vars (Instance 0)\n",
    "col_center = get_primary_column(df_raw, FIELD_IDS[\"CENTER\"])  # p54_i0\n",
    "col_ancestry = get_primary_column(df_raw, FIELD_IDS[\"ANCESTRY\"])  # p30079\n",
    "\n",
    "print(f\"Using Core Cols: {col_age}, {col_sex}, and {len(col_pcs)} PCs\")\n",
    "print(f\"Using Extended Cols: {col_center}, {col_ancestry}\")\n",
    "\n",
    "# Create Friendly Name Map for PCs\n",
    "pcs_map = {c: f\"PC{c.split('_a')[1]}\" for c in col_pcs}\n",
    "\n",
    "# --- 3. FILTERING (CORE ONLY) ---\n",
    "\n",
    "# We filter rows based ONLY on missing Core Data\n",
    "# We DO NOT drop rows if they are missing Center or Ancestry yet\n",
    "df_core_base = df_raw.na.drop(subset=[col_age, col_sex, col_center] + col_pcs)\n",
    "\n",
    "print(f\"Participants in Core Set: {df_core_base.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70c769c-595e-4736-ba2e-9ca13cf39d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply transformations to the base set\n",
    "df_processed = (\n",
    "    df_core_base.withColumn(\"FID\", F.col(\"eid\"))\n",
    "    .withColumn(\"IID\", F.col(\"eid\"))\n",
    "    .withColumn(\"SEX\", F.col(col_sex).cast(IntegerType()))\n",
    "    .withColumn(\"AGE\", F.col(col_age).cast(IntegerType()))\n",
    "    .withColumn(\"CENTER\", F.col(col_center).cast(IntegerType()))\n",
    "    .withColumn(\"ANCESTRY\", F.col(col_ancestry).cast(IntegerType()))\n",
    "    # Standard Interactions\n",
    "    .withColumn(\"AGE2\", (F.col(col_age) ** 2).cast(IntegerType()))\n",
    "    .withColumn(\"AGESEX\", (F.col(col_age) * F.col(col_sex)).cast(IntegerType()))\n",
    "    .withColumn(\"AGE2SEX\", ((F.col(col_age) ** 2) * F.col(col_sex)).cast(IntegerType()))\n",
    "    # Rename PCs\n",
    "    .select(\"*\", *[F.col(c).alias(pcs_map[c]) for c in col_pcs])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0860823-adc6-4761-9960-cd363b6184d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Rows: 487713\n",
      "+----------------+\n",
      "|Missing_Ancestry|\n",
      "+----------------+\n",
      "|           40073|\n",
      "+----------------+\n",
      "\n",
      "-RECORD 0--------------\n",
      " SEX      | 0          \n",
      " AGE      | 52         \n",
      " CENTER   | 11011      \n",
      " AGE2     | 2704       \n",
      " AGESEX   | 0          \n",
      " AGE2SEX  | 0          \n",
      " PC1      | -12.417    \n",
      " PC2      | 6.75787    \n",
      " PC3      | -4.42069   \n",
      " PC4      | 0.749104   \n",
      " PC5      | -1.30339   \n",
      " PC6      | 0.0162366  \n",
      " PC7      | 1.29456    \n",
      " PC8      | -1.45318   \n",
      " PC9      | -2.0664    \n",
      " PC10     | -2.42804   \n",
      " PC11     | -2.04608   \n",
      " PC12     | -0.119549  \n",
      " PC13     | -0.705609  \n",
      " PC14     | -1.9216    \n",
      " PC15     | 1.42809    \n",
      " PC16     | 3.75853    \n",
      " PC17     | 0.0576762  \n",
      " PC18     | -0.0193767 \n",
      " PC19     | 1.18116    \n",
      " PC20     | -1.58071   \n",
      " ANCESTRY | 5          \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_keep = (\n",
    "    [\"FID\", \"IID\", \"SEX\", \"AGE\", \"CENTER\", \"AGE2\", \"AGESEX\", \"AGE2SEX\"]\n",
    "    + list(pcs_map.values())\n",
    "    + [\"ANCESTRY\"]\n",
    ")\n",
    "\n",
    "# Sanity Check: Ensure counts match\n",
    "print(f\"Final Rows: {df_processed.count()}\")\n",
    "\n",
    "df_final = df_processed.select(*cols_keep)\n",
    "\n",
    "# Check for nulls in Ancestry\n",
    "df_final.select(\n",
    "    F.count(F.when(F.col(\"ANCESTRY\").isNull(), \"ANCESTRY\")).alias(\"Missing_Ancestry\")\n",
    ").show()\n",
    "\n",
    "df_final.drop(\"FID\", \"IID\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78202e40-1194-47e1-988d-95fa40dffeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to your own\n",
    "DX_PROJECT_PATH = \"TASR/Phenotypes/\"\n",
    "OUTPUT_FILENAME = \"Covariates.tsv\"\n",
    "\n",
    "\n",
    "def upload_df(df, filename: str, project_path: str, temp_dir: str = \"/tmp\"):\n",
    "    local_p = f\"{temp_dir}/{filename}\"\n",
    "    remote_p = f\"..{temp_dir}/{filename}\"\n",
    "\n",
    "    print(f\"Writing {filename}...\")\n",
    "    df.coalesce(1).write.csv(local_p, sep=\"\\t\", header=True, mode=\"overwrite\")\n",
    "\n",
    "    print(f\"Uploading {filename}...\")\n",
    "\n",
    "    # Define commands\n",
    "    commands = [\n",
    "        f\"hadoop fs -getmerge {local_p} {remote_p}\",\n",
    "        f\"dx upload {remote_p} --path {project_path}\",\n",
    "    ]\n",
    "\n",
    "    for cmd in commands:\n",
    "        print(f\"Running: {cmd}\")\n",
    "        # Run command and capture output\n",
    "        result = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "\n",
    "        # Print STDOUT (if any)\n",
    "        if result.stdout:\n",
    "            print(f\"[STDOUT]\\n{result.stdout}\")\n",
    "\n",
    "        # Print STDERR (if any)\n",
    "        if result.stderr:\n",
    "            print(f\"[STDERR]\\n{result.stderr}\")\n",
    "\n",
    "        # Check for failure\n",
    "        if result.returncode != 0:\n",
    "            print(f\"ERROR: Command failed with return code {result.returncode}\")\n",
    "            break\n",
    "\n",
    "\n",
    "upload_df(df_final, OUTPUT_FILENAME, DX_PROJECT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
