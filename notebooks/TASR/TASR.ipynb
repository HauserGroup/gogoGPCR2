{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd65bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import dxpy\n",
    "import hail as hl\n",
    "from datetime import datetime\n",
    "from matrixtables import import_mt, interval_qc_mt, smart_split_multi_mt\n",
    "from subprocess import run\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "\n",
    "Path(\"/tmp\").resolve().mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5134fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1db53a3f7f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Hail init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/cluster/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/spark/python/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/spark/python/pyspark/java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Spark and Hail \n",
    "\n",
    "DATABASE = \"matrix_tables\"\n",
    "REFERENCE_GENOME = 'GRCh38'\n",
    "PROJ_NAME = \"TASR\"\n",
    "\n",
    "LOG_FILE = (\n",
    "    Path(\"../hail_logs\", f\"{PROJ_NAME}_{datetime.now().strftime('%H%M')}.log\")\n",
    "    .resolve()\n",
    "    .__str__()\n",
    ")\n",
    "\n",
    "# Hail init\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "hl.init(sc=sc, default_reference=REFERENCE_GENOME, log=LOG_FILE)\n",
    "\n",
    "# Create database in DNAX\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DATABASE} LOCATION 'dnax://'\")\n",
    "mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101657b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGNC</th>\n",
       "      <th>entry_name</th>\n",
       "      <th>name</th>\n",
       "      <th>accession</th>\n",
       "      <th>family</th>\n",
       "      <th>species</th>\n",
       "      <th>residue_numbering_scheme</th>\n",
       "      <th>sequence</th>\n",
       "      <th>genes</th>\n",
       "      <th>ENSG</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>GRCh37_start</th>\n",
       "      <th>GRCh37_end</th>\n",
       "      <th>GRCh37_strand</th>\n",
       "      <th>GRCh38_start</th>\n",
       "      <th>GRCh38_end</th>\n",
       "      <th>GRCh38_strand</th>\n",
       "      <th>GRCh38_region</th>\n",
       "      <th>Notes</th>\n",
       "      <th>VCF_block</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TAS1R2</th>\n",
       "      <td>TAS1R2</td>\n",
       "      <td>ts1r2_human</td>\n",
       "      <td>&lt;i&gt;TAS1R2&lt;/i&gt;</td>\n",
       "      <td>Q8TE23</td>\n",
       "      <td>004_003_001_002</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPCRdb(C)</td>\n",
       "      <td>MGPRAKTISSLFFLLWVLAEPAENSDFYLPGDYLLGGLFSLHANMK...</td>\n",
       "      <td>['TAS1R2', 'GPR71', 'T1R2', 'TR2']</td>\n",
       "      <td>ENSG00000179002</td>\n",
       "      <td>...</td>\n",
       "      <td>GPCR</td>\n",
       "      <td>19166093.0</td>\n",
       "      <td>19186176.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18839599</td>\n",
       "      <td>18859682</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          HGNC   entry_name           name accession           family  \\\n",
       "HGNC                                                                    \n",
       "TAS1R2  TAS1R2  ts1r2_human  <i>TAS1R2</i>    Q8TE23  004_003_001_002   \n",
       "\n",
       "             species residue_numbering_scheme  \\\n",
       "HGNC                                            \n",
       "TAS1R2  Homo sapiens                GPCRdb(C)   \n",
       "\n",
       "                                                 sequence  \\\n",
       "HGNC                                                        \n",
       "TAS1R2  MGPRAKTISSLFFLLWVLAEPAENSDFYLPGDYLLGGLFSLHANMK...   \n",
       "\n",
       "                                     genes             ENSG  ...  type  \\\n",
       "HGNC                                                         ...         \n",
       "TAS1R2  ['TAS1R2', 'GPR71', 'T1R2', 'TR2']  ENSG00000179002  ...  GPCR   \n",
       "\n",
       "       GRCh37_start  GRCh37_end  GRCh37_strand  GRCh38_start  GRCh38_end  \\\n",
       "HGNC                                                                       \n",
       "TAS1R2   19166093.0  19186176.0           -1.0      18839599    18859682   \n",
       "\n",
       "        GRCh38_strand  GRCh38_region Notes VCF_block  \n",
       "HGNC                                                  \n",
       "TAS1R2             -1              1   NaN        14  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in metadata and region\n",
    "# Map genes to blocks and regions\n",
    "R2 = [\"TAS1R2\"]\n",
    "R3 = [\"TAS1R3\"]\n",
    "MAPPING_FILE = Path(\"../data/misc/mappings_with_blocks.tsv\").resolve()\n",
    "mapping = pd.read_csv(MAPPING_FILE, sep=\"\\t\").set_index(\"HGNC\", drop=False)\n",
    "mapping.loc[R2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bac7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gVCFs as Matrix Table and filter to only GENES\n",
    "\n",
    "VCF_DIR = Path(\"/mnt/project/Bulk/Exome sequences/Population level exome OQFE variants, pVCF format - final release/\")\n",
    "FIELD_ID = 23157 # UKB field ID for latest exome data\n",
    "\n",
    "mtR2 = import_mt(R2, mapping, vcf_dir=VCF_DIR, vcf_version=\"v1\", field_id=FIELD_ID).key_rows_by(\n",
    "    \"locus\", \"alleles\"\n",
    ")\n",
    "\n",
    "mtR3 = import_mt(R3, mapping, vcf_dir=VCF_DIR, vcf_version=\"v1\", field_id=FIELD_ID).key_rows_by(\n",
    "    \"locus\", \"alleles\"\n",
    ")\n",
    "\n",
    "mt = hl.MatrixTable.union_rows(mtR2, mtR3) # Workaround since this Hail is ancient and broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75846d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:18:27 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n"
     ]
    }
   ],
   "source": [
    "# Filter to only WES target regions \n",
    "INTERVAL_FILE=Path(\"../data/misc/xgen_plus_spikein.b38.bed\").resolve()\n",
    "run([\"hadoop\", \"fs\", \"-put\", str(INTERVAL_FILE), \"/tmp\"])\n",
    "\n",
    "interval_table = hl.import_bed(\n",
    "        f\"/tmp/{INTERVAL_FILE.name}\",\n",
    "        reference_genome=\"GRCh38\",\n",
    "    )\n",
    "\n",
    "mt = mt.filter_rows(hl.is_defined(interval_table[mt.locus]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6806bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:25:32 Hail: INFO: Coerced sorted dataset\n",
      "2023-03-23 09:35:59 Hail: INFO: Coerced sorted dataset\n",
      "2023-03-23 09:36:02 Hail: INFO: Coerced sorted dataset\n",
      "2023-03-23 09:47:30 Hail: INFO: wrote matrix table with 2032 rows and 469835 columns in 2 partitions to /tmp/TASR.INITIAL.cp.mt\n",
      "    Total size: 5.75 GiB\n",
      "    * Rows/entries: 5.75 GiB\n",
      "    * Columns: 3.07 MiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 861 rows (2.37 GiB)\n",
      "    * Largest partition:  1171 rows (3.38 GiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2032 variants and 469835 samples after import and target region filter\n"
     ]
    }
   ],
   "source": [
    "# Initial checkpoint\n",
    "stage = \"INITIAL\"\n",
    "checkpoint_file = f\"/tmp/{PROJ_NAME}.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=False)\n",
    "\n",
    "v, s = mt.count()\n",
    "print(f\"{v} variants and {s} samples after import and target region filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fae90d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448 variants with not more than 6 alleles after splitting\n"
     ]
    }
   ],
   "source": [
    "# Split multi alleles \n",
    "mt = mt.filter_rows(mt.alleles.length() <= 6)\n",
    "mt = smart_split_multi_mt(mt)\n",
    "\n",
    "print(f\"{mt.count_rows()} variants with not more than 6 alleles after splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b273d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:51:34 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-03-23 09:52:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    }
   ],
   "source": [
    "# Annotate with VEP and generate protein consequence\n",
    "VEP_JSON = Path(\"../data/misc/GRCh38_VEP.json\").resolve()\n",
    "\n",
    "mt = hl.vep(mt, f\"file:{VEP_JSON}\")\n",
    "\n",
    "is_MANE = mt.aggregate_rows(\n",
    "    hl.agg.all(hl.is_defined(mt.vep.transcript_consequences.mane_select))\n",
    ")\n",
    "assert is_MANE, \"Selected transcript may not be MANE Select. Check manually.\"\n",
    "\n",
    "mt = mt.annotate_rows(\n",
    "    protCons=mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[0]\n",
    "    + hl.str(mt.vep.transcript_consequences.protein_end[0])\n",
    "    + mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[-1],\n",
    "    gene = mt.vep.transcript_consequences.gene_symbol[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cd64353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:08:47 Hail: INFO: wrote matrix table with 2448 rows and 469835 columns in 6 partitions to /tmp/TASR.ANNOTATED.cp.mt\n",
      "2023-03-23 11:08:48 Hail: INFO: wrote matrix table with 2448 rows and 469835 columns in 6 partitions to /tmp/TASR.ANNOTATED.cp.mt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448 variants and 469835 samples after import and target region filter\n"
     ]
    }
   ],
   "source": [
    "# Initial checkpoint\n",
    "\n",
    "mt = mt.annotate_rows(gene = mt.vep.transcript_consequences.gene_symbol[0])\n",
    "\n",
    "stage = \"ANNOTATED\"\n",
    "checkpoint_file = f\"/tmp/{PROJ_NAME}.{stage}.cp.mt\"\n",
    "\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "\n",
    "v, s = mt.count()\n",
    "print(f\"{v} variants and {s} samples after import and target region filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58ba48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial checkpoint\n",
    "stage = \"ANNOTATED\"\n",
    "checkpoint_file = f\"/tmp/{PROJ_NAME}.{stage}.cp.mt\"\n",
    "\n",
    "mt = hl.read_matrix_table(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1547c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:28:37 Hail: INFO: Reading table without type imputation\n",
      "  Loading field '' as type str (not specified)\n",
      "  Loading field 'PC_UKBB.eid' as type str (not specified)\n",
      "  Loading field 'group' as type str (not specified)\n"
     ]
    }
   ],
   "source": [
    "run([\"hadoop\", \"fs\", \"-put\", \"ancestry.csv\", \"/tmp\"]) # from Ancestry.ipynb\n",
    "ht = hl.import_table(\"/tmp/ancestry.csv\", delimiter = \",\", quote='\"', missing=\"foo\").select(\"PC_UKBB.eid\", \"group\").key_by(\"PC_UKBB.eid\")\n",
    "# mt = mt.annotate_cols(**ht[mt.s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a25f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:24:27 Hail: INFO: Coerced sorted dataset\n",
      "2023-03-23 11:24:27 Hail: INFO: wrote table with 469835 rows in 16 partitions to /tmp/TASR.COLS.TAS1R3.HOM.cp.ht\n"
     ]
    }
   ],
   "source": [
    "GENE = \"TAS1R3\"\n",
    "ZYG = \"HOM\"\n",
    "mtr2 = mt.filter_rows((mt.gene == GENE) & (mt.vep.most_severe_consequence == \"missense_variant\"))\n",
    "mtr2 = mtr2.annotate_cols(\n",
    "#                      tas1r2_het = hl.agg.filter(mtr2.GT.is_het_ref(), hl.agg.collect(mtr2.protCons)),\n",
    "#                      tas1r2_hom = hl.agg.filter(mtr2.GT.is_hom_var(), hl.agg.collect(mtr2.protCons)),\n",
    "#                      tas1r3_het = hl.agg.filter(mtr2.GT.is_het_ref(), hl.agg.collect(mtr2.protCons)),\n",
    "                     tas1r3_hom = hl.agg.filter(mtr2.GT.is_hom_var(), hl.agg.collect(mtr2.protCons))\n",
    "                     )\n",
    "\n",
    "stage = \"COLS\"\n",
    "checkpoint_file = f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\"\n",
    "htr2 = mtr2.cols()\n",
    "htr2 = htr2.checkpoint(checkpoint_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58334d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"COLS\"\n",
    "\n",
    "GENE = \"TAS1R2\"\n",
    "ZYG = \"HET\"\n",
    "f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\"\n",
    "\n",
    "ht1 = hl.read_table(f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\").key_by(\"s\")\n",
    "\n",
    "GENE = \"TAS1R2\"\n",
    "ZYG = \"HOM\"\n",
    "\n",
    "ht2 = hl.read_table(f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\").key_by(\"s\")\n",
    "\n",
    "GENE = \"TAS1R3\"\n",
    "ZYG = \"HET\"\n",
    "\n",
    "ht3 = hl.read_table(f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\").key_by(\"s\")\n",
    "\n",
    "GENE = \"TAS1R3\"\n",
    "ZYG = \"HOM\"\n",
    "\n",
    "ht4 = hl.read_table(f\"/tmp/{PROJ_NAME}.{stage}.{GENE}.{ZYG}.cp.ht\").key_by(\"s\")\n",
    "\n",
    "ht = ht.join(ht1).join(ht2).join(ht3).join(ht4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f6e09af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:33:54 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-03-23 11:34:13 Hail: INFO: merging 16 files totalling 26.3M...\n",
      "2023-03-23 11:34:13 Hail: INFO: while writing:\n",
      "    TASR_Haplotypes.tsv\n",
      "  merge time: 282.482ms\n"
     ]
    }
   ],
   "source": [
    "ht = ht.add_index()\n",
    "ht = ht.key_by().drop('PC_UKBB.eid')\n",
    "ht.export(\"TASR_Haplotypes.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09904964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'fs', '-get', 'TASR_Haplotypes.tsv'], returncode=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run([\"hadoop\", \"fs\", \"-get\", \"TASR_Haplotypes.tsv\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d27ec8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:40:31 Hail: INFO: merging 4 files totalling 415.6K...\n",
      "2023-03-23 11:40:31 Hail: INFO: while writing:\n",
      "    /tmp/TARS_Variants.tsv\n",
      "  merge time: 41.434ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'fs', '-get', '/tmp/TARS_Variants.tsv'], returncode=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary of variants\n",
    "mt = hl.variant_qc(mt)\n",
    "intr = mt.rows()\n",
    "intr = intr.select(intr.gene, intr.variant_qc, intr.protCons, intr.vep.most_severe_consequence)\n",
    "intr = intr.annotate(**intr.variant_qc)\n",
    "intr = intr.drop(\n",
    "    \"variant_qc\",\n",
    "    \"gq_stats\",\n",
    "    \"dp_stats\",\n",
    ")\n",
    "intr.export('/tmp/TARS_Variants.tsv')\n",
    "run([\"hadoop\", \"fs\", \"-get\", '/tmp/TARS_Variants.tsv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b294dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
